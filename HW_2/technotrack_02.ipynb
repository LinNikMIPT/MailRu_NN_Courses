{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №2: Глубинные нейронные сети. Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пожалуйста, заполните имя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_NAME = \"FirstName LastName\" # For example, Fedor Petriaikin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Включает режим проверки\n",
    "try:\n",
    "    import train_utils\n",
    "    TEST_MODE = True\n",
    "except:\n",
    "    TEST_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.nn import MSELoss, Sequential, Linear, Sigmoid, Tanh\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Не удаляйте клетки из этого jupyter-notebok! Это затруднит проверку!**\n",
    "\n",
    "В этом задании вам предстоит попробовать обучить нейронную сеть с помощью фреймворка Pytorch, изучить подходы к инициализации нейронных сетей и реализовать слои, улучшающие сходимость глубинных нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1. Введение в Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя датасет из архива решите задачу регрессии для поиска 68-ми ключевых точек лица.  \n",
    "Для обучения и валидации используйте изображения и разметку из папок train и test соответственно.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример работы с датасетом\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "landmarks_frame = pd.read_csv('dataset/train/face_landmarks.csv')\n",
    "\n",
    "n = 100\n",
    "img_name = landmarks_frame.ix[n, 0]\n",
    "landmarks = landmarks_frame.ix[n, 1:].as_matrix().astype('float')\n",
    "landmarks = landmarks.reshape(-1, 2)\n",
    "\n",
    "print('Image name: {}'.format(img_name))\n",
    "print('Landmarks shape: {}'.format(landmarks.shape))\n",
    "print('First 4 Landmarks: {}'.format(landmarks[:4]))\n",
    "\n",
    "def show_landmarks(image, landmarks):\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='red', cmap='rgb')\n",
    "    plt.pause(0.001)  \n",
    "\n",
    "plt.figure()\n",
    "show_landmarks(io.imread(os.path.join('dataset/train/', img_name)),\n",
    "               landmarks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Далее нам нужно сформировать свой датасет\n",
    "# См. https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "class FaceLandmarksDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    # Из этой функции нужно вернуть dict вида {'image': image, 'landmarks': landmarks}\n",
    "    # Где image и landmarks - получаются так же, как в функции выше\n",
    "    # Не забудьте применить transform - это нужно для превращения в тензор\n",
    "    def __getitem__(self, idx):\n",
    "        ### YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Превращение в torch.Tensor лучше делать как отдельное преобразование -\n",
    "# это позволит работать с датасетом не только в рамках pytorch\n",
    "# Выходом преобразования должны быть (X, y) - 2 одномерных тензора torch.FloatTensor\n",
    "# Для этого воспользуйтеь методом ndarray.ravel()\n",
    "# Получающиеся размерности X = torch.Size([9216]), y = torch.Size([136])\n",
    "\n",
    "# Обратите внимание на типы тензоров в pytorch! Это очень важный их параметр!\n",
    "# См. https://pytorch.org/docs/stable/tensors.html#torch.Tensor.type\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    # Превращает во FloatTensor входные данные и \"вытягивает\" размерности в одну строку\n",
    "    # (т.к. у нас не сверточные сети - нет смысла хранить размерности)\n",
    "    def __call__(self, sample):\n",
    "        ### YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если не отделять папку dataset от этого notebook, то этот код\n",
    "# 1) должен создать train и test\n",
    "train_dataset = FaceLandmarksDataset(csv_file='dataset/train/face_landmarks.csv',\n",
    "                                     root_dir='dataset/train',\n",
    "                                     transform=ToTensor() # Чтобы получить тензоры\n",
    "                                     )\n",
    "test_dataset = FaceLandmarksDataset(csv_file='dataset/test/face_landmarks.csv',\n",
    "                                     root_dir='dataset/test',\n",
    "                                     transform=ToTensor()\n",
    "                                     )\n",
    "\n",
    "# 2) сформировать dataloader-ы \n",
    "# См. https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64,\n",
    "                        shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте сети глубины 1 и 2 и разные активации (ELU, RELU и sigmoid). Loss - MSE, оптимизатор - Adam с learning rate 0.1 (остальные параметры оптимизатора по умолчанию). Обучайте сети в течении 4 эпох - нам не нужно здесь качество  \n",
    "Для каждой архитектуры постройте графики для функции потерь на train/test\n",
    "\n",
    "\n",
    "В этом задании **нет** порога качества - оно нужно, чтобы освоиться с pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_train(network, train_dataloader, test_dataloader, epochs):\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=0.1)\n",
    "    loss = MSELoss()\n",
    "    ### YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Массив из nn.Sequential - сетей для обучения\n",
    "networks = [] ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Должен построить графики и написать значение MSE на train и test для каждой из архитектур\n",
    "for n in networks:\n",
    "    simple_train(n, train_dataloader, test_dataloader, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка\n",
    "if TEST_MODE:\n",
    "    from importlib import reload\n",
    "    reload(train_utils)\n",
    "\n",
    "    for n in networks:\n",
    "        train_utils.train(n, train_dataloader, test_dataloader, 4, MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на предикт\n",
    "\n",
    "def show_landmarks_batch(sample_batch, y_pred=None):\n",
    "    \"\"\"Show image with landmarks for a batch of samples.\"\"\"\n",
    "    images_batch, landmarks_batch = sample_batch\n",
    "    batch_size = len(images_batch)\n",
    "\n",
    "    images_batch = images_batch.view(-1, 96, 96)\n",
    "    landmarks_batch = landmarks_batch.view(-1, 68, 2)\n",
    "    im_size = images_batch.size(2)\n",
    "\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose(1,0,2).reshape(im_size, -1), cmap=\"gray\")\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size,\n",
    "                    landmarks_batch[i, :, 1].numpy(),\n",
    "                    s=10, marker='.', c='r', label='Real')\n",
    "\n",
    "    if type(y_pred) != type(None):\n",
    "        for i in range(batch_size):\n",
    "            plt.scatter(y_pred[i, :, 0] + i * im_size,\n",
    "                        y_pred[i, :, 1],\n",
    "                        s=10, marker='.', c='b',  label='Prediction')\n",
    "        plt.title('Batch from dataloader')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_nw_pos = None # Выберите номер лучшей архитектуры в списке networks\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
    "batch = next(iter(test_dataloader))\n",
    "x = batch[0]\n",
    "y_pred = networks[0](x)\n",
    "y = batch[1]\n",
    "y_pred = y_pred.view(-1, 68, 2)\n",
    "y_pred = y_pred.data.numpy()\n",
    "show_landmarks_batch(batch, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2. Инициализация нейронных сетей\n",
    "В этом задании мы вернемся к нашему знакомому датасету MNIST. Напомним:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "to_numpy = lambda x: x.numpy()\n",
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])\n",
    "train_dataset = MNIST('.', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST('.', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовые батчи. Нарисуем их, а потом будем пропускать их через нейронную сеть\n",
    "images_train, labels_train = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 7))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(images_train.numpy()[i].reshape(28, 28), cmap=plt.cm.Greys_r)\n",
    "    plt.title(labels_train.numpy()[i])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нам понадобятся некоторые вспомогательные функции для распечатки градиентов\n",
    "\n",
    "ITER = 0\n",
    "def forward_hook(self, input_, output):\n",
    "    global ITER\n",
    "    std = input_[0].std().item()\n",
    "    print(ITER, ': forward', std)\n",
    "    ITER += 1\n",
    "\n",
    "def backward_hook(self, grad_input, grad_output):\n",
    "    global ITER\n",
    "    std = grad_input[0].std().item()\n",
    "    print(ITER, ': backward', std)\n",
    "    ITER -= 1\n",
    "\n",
    "# Пользоваться ими можно так (пример функтора создания слоя)\n",
    "def create_sample_linear(inp_size, out_size):\n",
    "    layer = nn.Linear(inp_size, out_size)\n",
    "    layer.register_forward_hook(forward_hook)\n",
    "    layer.register_backward_hook(backward_hook)\n",
    "    \n",
    "    weight = layer.state_dict()['weight']\n",
    "    bias = layer.state_dict()['bias']\n",
    "    bias.zero_()\n",
    "    weight.normal_(mean=0, std=0.1)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция пропуска тестового батча через нейронную сеть\n",
    "def sample_propagation(network):\n",
    "    global ITER\n",
    "    ITER = 0\n",
    "\n",
    "    n_objects = 100\n",
    "    X = images_train[:n_objects].view(n_objects, -1)\n",
    "    y = labels_train[:n_objects]\n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "    activations = network(X)\n",
    "    loss_fn = torch.nn.NLLLoss()\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=0.001) \n",
    "    loss = loss_fn(activations, y)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция создания тестовой нейронной сети. Следует создавать 200 промежуточных слоев (и activation между ними)\n",
    "# Принимает функторы создания слоев с \"говорливыми\" hook-ами (см. пример функтора создания слоя выше),\n",
    "# возвращает nn.Sequential из них\n",
    "# Не забывайте про *list для распаковки списков в параметры\n",
    "\n",
    "# layers_creator - принимает массив, добавляет в него новый линейный промежуточный слой 500x500\n",
    "# start_layer_creator - принимает массив, добавляет в него первый слой (784 --> 500)\n",
    "# end_layer_creator - принимает массив, добавляет в него последний слой (500 --> 10)\n",
    "\n",
    "def create_network(layers_creator,\n",
    "                   start_layer_creator=lambda layers: layers.append(create_sample_linear(784, 500)),\n",
    "                   end_layer_creator=lambda layers: layers.append(create_sample_linear(500, 10)),\n",
    "                   activation=nn.Tanh):\n",
    "    ### YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте функторы создания слоев (линейных, 500x500):  \n",
    "1. Инициализированных N(0, 0.1) - см. create_sample_linear\n",
    "2. Инициализированных по He\n",
    "3. Инициализированных по Xavier\n",
    "\n",
    "Обучите нейронные сети с каждым из методов инициализации. Архитектура - 784 -> 500 x (200 раз) -> 10. В качестве активации возьмите tanh (1-2), ReLU (Xavier). Посмотрите как изменяются градиенты на forward и backward (с помощью sample_propagation). Сделайте выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_propagation(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Выводы:*\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спасибо за выполнение заданий!  \n",
    "\n",
    "**Обратите внимание:**  \n",
    "Еще 2 обязательных задания этого модуля - batchnorm и dropout - находятся в следующем jupyter notebook (скоро будет отправлен). Также будет отправлено необязательное задание по методам оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
